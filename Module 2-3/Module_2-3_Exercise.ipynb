{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling and Feature Engineering Exercise\n",
    "\n",
    "Place your answers within the code blocks that have the comment.\n",
    "\n",
    "```python\n",
    "# your code here\n",
    "```\n",
    "\n",
    "Make sure to remove or comment the line below to be able to proceed. It's only placed there as a reminder that the function has not yet been implemented.\n",
    "\n",
    "```python\n",
    "raise NotImplementedError\n",
    "```\n",
    "\n",
    "## Note on \"test scripts\"\n",
    "\n",
    "The code block following the function definition are \"unit tests\" which are code blocks which test if the function you implemented is correct or not. It will not print an output **if the conditions are met** (meaning the answer is correct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston Dataset\n",
    "\n",
    "We will be using the boston house pricing dataset for exercises 1-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data_bunch = load_boston()\n",
    "data = data_bunch['data']\n",
    "feature_names = data_bunch['feature_names']\n",
    "descr = data_bunch['DESCR']\n",
    "\n",
    "df = pd.DataFrame(data, columns=feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(descr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Change the data type of `CHAS` column to **int** and apply one-hot encoding using `pandas`. **(2 pts.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "# your code here\n",
    "df1['CHAS'] = df1.CHAS.astype('int')\n",
    "df1 = pd.get_dummies(df1, columns=['CHAS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df1.columns.tolist()==['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', \n",
    "                              'TAX', 'PTRATIO', 'B', 'LSTAT', 'CHAS_0', 'CHAS_1']\n",
    "assert df1['CHAS_0'].values[150:170].tolist()==[1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "assert df1['CHAS_1'].values[150:170].tolist()==[0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** Filter out the entries wherein the crime rate is lower than the mean. **(2 pts.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "# your code here\n",
    "df2 = df2[(df2.CRIM > df2['CRIM'].mean())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df2.shape==(128, 13)\n",
    "assert df2.values[0].tolist()==[4.0974, 0.0, 19.58, 0.0, 0.871, 5.468, 100.0, 1.4118, 5.0, 403.0, 14.7, 396.9, 26.42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.** Change the values of `RAD` column based on the following rules: **(4 pts.)**\n",
    " - if 1 to 4, change it to 1.\n",
    " - if 5 to 8, change it to 2.\n",
    " - otherwise, change it to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "# your code here\n",
    "\n",
    "m1 = (df3.RAD <=4)\n",
    "m2 = (df3.RAD <=8)\n",
    "m3 = (df3.RAD >9)\n",
    "\n",
    "df3['RAD'] = np.select([m1, m2, m3], [1, 2, 3], default='other')\n",
    "df3['RAD'] = df3.RAD.astype(np.int64)\n",
    "\n",
    "#df3.RAD.value_counts().to_dict()\n",
    "\n",
    "#df3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df3['RAD'].value_counts().to_dict()=={1: 192, 2: 182, 3: 132}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.** Using the dataframe output from exercise 3, group the entries based on `RAD` column, and get the mean of crime rates for each group. You should end up with a `Series` data structure. Please refer to the assert to have an idea of what is expected. **(2 pts.)**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "# your code here\n",
    "\n",
    "df4 = df4.groupby('RAD').CRIM.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df4.to_dict()=={1: 0.2591065625, 2: 0.5190552747252744, 3: 12.759290909090915}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.** Using the dataframe output from exercise 3, group the entries based on `RAD` column, and get the following statistics: count, mean, std, min, 25%, 50%, 75%, and max crime rates for each group. Have all those statistics as column names for the columns of the new `DataFrame`. This means your DataFrame will have the following columns: **count mean std min 25% 50% 75% max**. Please refer to the assert to have an idea of what is expected. \n",
    "**(2 pts.)**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.0</td>\n",
       "      <td>0.259107</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.045107</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>0.274423</td>\n",
       "      <td>2.63548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182.0</td>\n",
       "      <td>0.519055</td>\n",
       "      <td>0.786160</td>\n",
       "      <td>0.01311</td>\n",
       "      <td>0.087375</td>\n",
       "      <td>0.171525</td>\n",
       "      <td>0.525343</td>\n",
       "      <td>4.09740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132.0</td>\n",
       "      <td>12.759291</td>\n",
       "      <td>13.041169</td>\n",
       "      <td>2.37857</td>\n",
       "      <td>5.686307</td>\n",
       "      <td>9.084990</td>\n",
       "      <td>14.333700</td>\n",
       "      <td>88.97620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count       mean        std      min       25%       50%        75%  \\\n",
       "RAD                                                                        \n",
       "1    192.0   0.259107   0.379949  0.00632  0.045107  0.094515   0.274423   \n",
       "2    182.0   0.519055   0.786160  0.01311  0.087375  0.171525   0.525343   \n",
       "3    132.0  12.759291  13.041169  2.37857  5.686307  9.084990  14.333700   \n",
       "\n",
       "          max  \n",
       "RAD            \n",
       "1     2.63548  \n",
       "2     4.09740  \n",
       "3    88.97620  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = df3.copy()\n",
    "# your code here\n",
    "df5 = df5.groupby('RAD').CRIM.describe()\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df5.to_dict()=={'count': {1: 192.0, 2: 182.0, 3: 132.0},\n",
    " 'mean': {1: 0.2591065625, 2: 0.5190552747252748, 3: 12.75929090909091},\n",
    " 'std': {1: 0.3799485400326451, 2: 0.7861597586426312, 3: 13.0411694541406},\n",
    " 'min': {1: 0.00632, 2: 0.01311, 3: 2.37857},\n",
    " '25%': {1: 0.045107499999999995, 2: 0.087375, 3: 5.6863075},\n",
    " '50%': {1: 0.094515, 2: 0.17152499999999998, 3: 9.084990000000001},\n",
    " '75%': {1: 0.2744225, 2: 0.5253425, 3: 14.3337},\n",
    " 'max': {1: 2.63548, 2: 4.0974, 3: 88.9762}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Dataset\n",
    "\n",
    "For the following items, we will use the titanic dataset. For more details regarding the dataset, see this link: https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('titanic.csv')\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6.** Let's do some feature engineering on the `Name` column, which has the following format:\n",
    "```<Surname>, <Title> <Name> <Middle Name>```.\n",
    "\n",
    "Your task is to transform the whole text to just the **Surname**. For example, ***Braund*, Mr. Owen Harris** will become ***Braund*** and ***Heikkinen*, Miss. Laina** will become ***Heikkinen***.\n",
    "\n",
    "Hint! Use the built-in `split` function in string data types.\n",
    "\n",
    "**(3 pts.)**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df_titanic.copy()\n",
    "\n",
    "split = df6['Name'].str.split(\",\")\n",
    "df6['Name'] = split.str[0]\n",
    "\n",
    "#df6['Name'].tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df6['Name'].tolist()[:10]==['Braund', 'Cumings', 'Heikkinen', 'Futrelle', 'Allen', \n",
    "                                   'Moran', 'McCarthy', 'Palsson', 'Johnson', 'Nasser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.** Again, the focus is on column `Name`. Let's assume that the following format holds true for all instances:\n",
    "```<Surname>, <Title> <Name> <Middle Name>```.\n",
    "\n",
    "Your task is to create new columns named **Surname** and **Title** containing the corresponding extracted details. For example, ***Braund*, *Mr.* Owen Harris** will get us ***Braund*** for the surname and ***Mr.*** for the title, and ***Heikkinen*, *Miss.* Laina** will get us ***Heikkinen*** for the surname and ***Miss.*** for the title.\n",
    "\n",
    "Hint! Use the built-in `split` function in string data types.\n",
    "\n",
    "Source: https://stackoverflow.com/questions/54053180/how-to-split-names-using-regular-expression-in-pandas-dataframe\n",
    "\n",
    "\n",
    "**(3 pts.)**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df_titanic.copy()\n",
    "# your code here\n",
    "split = df7['Name'].str.split(\",\")\n",
    "df7['Surname'] = split.str[0]\n",
    "df7['Title'] = split.str[1]\n",
    "df_7 = df7[\"Title\"].str.split(\" \", n = -1, expand = True) \n",
    "df7[\"Title\"]= df_7[1]   \n",
    "\n",
    "#df7[['Surname','Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df7['Surname'].tolist()[:10]==['Braund', 'Cumings', 'Heikkinen', 'Futrelle', 'Allen', \n",
    "                                      'Moran', 'McCarthy', 'Palsson', 'Johnson', 'Nasser']\n",
    "assert df7['Title'].tolist()[:10]==['Mr.', 'Mrs.', 'Miss.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Master.', 'Mrs.', 'Mrs.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8.** Drop all entries with null values, and then get the cabin letter from the `Cabin` column by simply retrieving the first letter in the string. Assign that into a new column named `CabinLetter`. Lastly, filter out the male entries.\n",
    "\n",
    "**(4 pts.)**\n",
    "\n",
    "source: https://stackoverflow.com/questions/56696680/string-split-on-capital-letters-a-large-dataframe-columnhttps://stackoverflow.com/questions/56696680/string-split-on-capital-letters-a-large-dataframe-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df_titanic.copy()\n",
    "# your code here\n",
    "\n",
    "df8 = df8[(df8.Sex == 'female')].dropna()\n",
    "split = df8['Cabin'].str.split('[0-9]')\n",
    "df8['CabinLetter'] = split.str[0]\n",
    "#df8.CabinLetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df8.shape==(88, 13) \n",
    "assert df8.head().to_dict()=={'PassengerId': {1: 2, 3: 4, 10: 11, 11: 12, 52: 53},\n",
    " 'Survived': {1: 1, 3: 1, 10: 1, 11: 1, 52: 1},\n",
    " 'Pclass': {1: 1, 3: 1, 10: 3, 11: 1, 52: 1},\n",
    " 'Name': {1: 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)',\n",
    "  3: 'Futrelle, Mrs. Jacques Heath (Lily May Peel)',\n",
    "  10: 'Sandstrom, Miss. Marguerite Rut',\n",
    "  11: 'Bonnell, Miss. Elizabeth',\n",
    "  52: 'Harper, Mrs. Henry Sleeper (Myna Haxtun)'},\n",
    " 'Sex': {1: 'female', 3: 'female', 10: 'female', 11: 'female', 52: 'female'},\n",
    " 'Age': {1: 38.0, 3: 35.0, 10: 4.0, 11: 58.0, 52: 49.0},\n",
    " 'SibSp': {1: 1, 3: 1, 10: 1, 11: 0, 52: 1},\n",
    " 'Parch': {1: 0, 3: 0, 10: 1, 11: 0, 52: 0},\n",
    " 'Ticket': {1: 'PC 17599',\n",
    "  3: '113803',\n",
    "  10: 'PP 9549',\n",
    "  11: '113783',\n",
    "  52: 'PC 17572'},\n",
    " 'Fare': {1: 71.2833, 3: 53.1, 10: 16.7, 11: 26.55, 52: 76.7292},\n",
    " 'Cabin': {1: 'C85', 3: 'C123', 10: 'G6', 11: 'C103', 52: 'D33'},\n",
    " 'Embarked': {1: 'C', 3: 'S', 10: 'S', 11: 'S', 52: 'C'},\n",
    " 'CabinLetter': {1: 'C', 3: 'C', 10: 'G', 11: 'C', 52: 'D'}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
